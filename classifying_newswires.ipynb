{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifying newswires.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZ0gTnBAEXmIHw1GVF2kgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WeiHao-19/deep-learning-with-python-notebooks/blob/master/classifying_newswires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv4QGirLwYHm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "574644db-cd96-4a84-9192-d15ebb8244bd"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXKqEHCj381G"
      },
      "source": [
        "**路透社数据集**它包括46个不同的主题：某些主题的样本更多，但训练集中每个主题都有至少10 个样本。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34iDOX_K4Pf0",
        "outputId": "d569f058-dc35-4576-f4a2-050755ac3533"
      },
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkKJ5LGV4sr1"
      },
      "source": [
        "与IMDB数据集一样，参数 num_words=10000 将数据限定为前 10000 个最常出现的单词。\n",
        "我们有 8982 个训练样本和 2246 个测试样本。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7NQF8AH4nj_",
        "outputId": "8c4ab821-0364-4441-ea83-1f158e34830e"
      },
      "source": [
        "len(train_data)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taGGc8-E5I5b",
        "outputId": "1f7d7dd1-9db9-4b1a-99e5-1e11bcc8ce5a"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHcIlJqn5SFo",
        "outputId": "59832b8e-df6f-4ad3-f033-dfa561f710a4"
      },
      "source": [
        "train_data[22]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 71,\n",
              " 8,\n",
              " 16,\n",
              " 385,\n",
              " 6,\n",
              " 42,\n",
              " 904,\n",
              " 103,\n",
              " 727,\n",
              " 27,\n",
              " 682,\n",
              " 7879,\n",
              " 451,\n",
              " 18,\n",
              " 79,\n",
              " 5,\n",
              " 49,\n",
              " 175,\n",
              " 80,\n",
              " 9,\n",
              " 1379,\n",
              " 6,\n",
              " 406,\n",
              " 42,\n",
              " 549,\n",
              " 451,\n",
              " 18,\n",
              " 79,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 587,\n",
              " 848,\n",
              " 4,\n",
              " 1651,\n",
              " 310,\n",
              " 22,\n",
              " 134,\n",
              " 72,\n",
              " 20,\n",
              " 6,\n",
              " 196,\n",
              " 44,\n",
              " 20,\n",
              " 4,\n",
              " 39,\n",
              " 1154,\n",
              " 6,\n",
              " 4,\n",
              " 49,\n",
              " 135,\n",
              " 32,\n",
              " 63,\n",
              " 11,\n",
              " 15,\n",
              " 4,\n",
              " 49,\n",
              " 8,\n",
              " 4,\n",
              " 1379,\n",
              " 55,\n",
              " 2,\n",
              " 117,\n",
              " 4,\n",
              " 225,\n",
              " 109,\n",
              " 206,\n",
              " 28,\n",
              " 258,\n",
              " 132,\n",
              " 15,\n",
              " 90,\n",
              " 67,\n",
              " 5,\n",
              " 175,\n",
              " 80,\n",
              " 519,\n",
              " 6,\n",
              " 2,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwm1XJmA5ZzG"
      },
      "source": [
        "拉片train_data中sequence中的第23个"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBopRC75nZy"
      },
      "source": [
        "# word_index 是一个将单词映射为整数索引的字典\n",
        "word_index = reuters.get_word_index()\n",
        "# 通过reverse，键值颠倒，把整数索引映射为单词\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# Note我们的索引indics减去了‘3’\n",
        "# 因为 0, 1  2 是为 填充\"padding\", 序列开始\"start of sequence\", 和未知词\"unknown\"分别保留的索引.\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "eYd1kD847m07",
        "outputId": "9462d12f-55a3-4111-9cdd-261215284e0a"
      },
      "source": [
        "# 将其中一条newswire解码处理看看，可以看出‘？？？’说明全部的newswires已经成功解码\n",
        "decoded_newswire"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G7QGbLf8e_4",
        "outputId": "c4bfdf30-6a76-4515-9a38-830fc3a7549d"
      },
      "source": [
        "# 注意labels永远是一组标量\n",
        "train_labels[22]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Eqqum-8FpM"
      },
      "source": [
        "# 准备数据\n",
        "# 此处就是编码数据，使其向量化\n",
        "import numpy as np\n",
        "\n",
        "# 定义（创建）一个矩阵，这个矩阵以sequences为长，以10000维度为宽\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "# 进入for循环，对于enumerate列举出的i条sequences，将results[i]的指定索引设为1\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "# 我们的训练数据vectorized\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 我们的测试数据vectorized\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae7mnFtf-goN"
      },
      "source": [
        "# 将标签向量化有两种方法：\n",
        "# 1.将标签列表转换为整数张量，\n",
        "# 2.使用 one-hot 编码。\n",
        "# one-hot 编码是分类数据广泛使用的一种格式，也叫分类编码（categorical encoding）。在这个例子中，标签的 one-hot 编码就是将每个标签表示为*全零向量*，\n",
        "# 只有标签索引对应的元素为 1。其代码实现如下：\n",
        "# 从keras的np函数集合中导入\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeDx2p-g_rXD"
      },
      "source": [
        "# 这一步构建网络\n",
        "# 考虑到这个主题分类问题是对简短的文本片段进行分类，但这个问题有一个新的约束条件：输出类别的数量从 2 个（二分类）变为 46 个（多分类）。\n",
        "# 输出空间的维度要大得多。\n",
        "# 故而不能简单的使用 Dense 层的堆叠，（因为每层只能访问上一层输出的信息）。\n",
        "# 如果某一层丢失了与分类问题相关的一些信息，那么这些信息无法被后面的层找回，也就是说，每一层都可能成为信息瓶颈。（猜测隐含层数量要求极高）\n",
        "# 因此，此例中，我们不再简单使用 16 维的中间层，对这个例子来说 16 维空间可能太小了，无法学会区分 46 个不同的类别。这种维度较小的层可能成为信息瓶颈，永久地丢失相关信息。\n",
        "# 出于这个原因，下面将使用维度更大的层，包含 64 个单元。（这种解决思路无论在算力解放与否的情况下，大规模使用都只能算是一种为保守地维持鲁棒性而几何级压榨算力）\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhfzbYVaBhct"
      },
      "source": [
        "### 关于这个架构还应该注意另外两点。\n",
        "- 网络的最后一层是大小为 46 的 Dense 层。这意味着，对于每个输入样本，网络都会输\n",
        "出一个 46 维向量。这个向量的每个元素（即每个维度）代表不同的输出类别。\n",
        "- 最后一层使用了 softmax 激活。这种用法是指网络将输出在 46 个不同输出类别上的概率分布——对于每一个输入样本，网络都会输出一个 46 维向量（对接上文一点），其中 output[i] 是样本属于第 i 个类别的概率。46 个概率的总和为 1。对于这个例子，最好的损失函数是 categorical_crossentropy（分类交叉熵）。它用于衡量两个概率分布之间距离，这里两个概率分布分别是网络输出的概率分布和标签的真实分布。通过将这两个分布的距离最小化，训练网络可使输出结果尽可能接近真实标签。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQg1V8iVBeEO"
      },
      "source": [
        "# 编译模型\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld2mEWPdCsAE"
      },
      "source": [
        "# 这一步再在训练集中切出1000个来作为验证集\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmVuRq-fC9eS",
        "outputId": "ad6546f0-1c81-4eca-8f40-0ab374750139"
      },
      "source": [
        "# 开始training，共计20个epochs\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 2s 64ms/step - loss: 3.0915 - accuracy: 0.4398 - val_loss: 1.7155 - val_accuracy: 0.6480\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 1.4862 - accuracy: 0.6891 - val_loss: 1.3087 - val_accuracy: 0.7060\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.1014 - accuracy: 0.7608 - val_loss: 1.1460 - val_accuracy: 0.7430\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.8774 - accuracy: 0.8111 - val_loss: 1.0480 - val_accuracy: 0.7740\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.6970 - accuracy: 0.8538 - val_loss: 0.9723 - val_accuracy: 0.8000\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.5593 - accuracy: 0.8825 - val_loss: 0.9850 - val_accuracy: 0.7800\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.4733 - accuracy: 0.9015 - val_loss: 0.9278 - val_accuracy: 0.8110\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.3759 - accuracy: 0.9216 - val_loss: 0.9045 - val_accuracy: 0.8120\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.3060 - accuracy: 0.9340 - val_loss: 0.8883 - val_accuracy: 0.8240\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.2507 - accuracy: 0.9449 - val_loss: 0.8950 - val_accuracy: 0.8240\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.2198 - accuracy: 0.9500 - val_loss: 0.9909 - val_accuracy: 0.8050\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1874 - accuracy: 0.9519 - val_loss: 0.9680 - val_accuracy: 0.8040\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1495 - accuracy: 0.9610 - val_loss: 0.9382 - val_accuracy: 0.8190\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1420 - accuracy: 0.9610 - val_loss: 0.9489 - val_accuracy: 0.8180\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.1345 - accuracy: 0.9582 - val_loss: 1.0073 - val_accuracy: 0.8130\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1250 - accuracy: 0.9614 - val_loss: 1.0236 - val_accuracy: 0.8180\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1146 - accuracy: 0.9627 - val_loss: 1.0100 - val_accuracy: 0.8230\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1096 - accuracy: 0.9629 - val_loss: 1.0650 - val_accuracy: 0.8060\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.1080 - accuracy: 0.9582 - val_loss: 1.0507 - val_accuracy: 0.8080\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0933 - accuracy: 0.9684 - val_loss: 1.0809 - val_accuracy: 0.8060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LoRiiAFkDT-P",
        "outputId": "7400b766-4f66-495b-8db3-a54199a90214"
      },
      "source": [
        "# 绘制损失曲线loss curves和精度曲线accuracy curves看看效果咯\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhpSRXc5Drus"
      },
      "source": [
        "这一步就能看出 20个epochs 可谓是处心积虑而恰到好处，既能得到较好的预期泛化，又能减轻算力负担"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xyLOPXRnEf-n",
        "outputId": "19b91524-9405-48e5-9b5f-f664018aea4a"
      },
      "source": [
        "# 再来看看训练精度和验证精度\n",
        "plt.clf()   # 清除上一步的训练损失和验证损失 figure\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTUet-NIJDhO",
        "outputId": "e6b1482d-d717-4d2c-9bd9-c9a8b337de77"
      },
      "source": [
        "# 网络在epoch 8、9 轮后开始过拟合。我们从头开始训练一个新网络，共 8 个轮次，然后在测试集上评估模型。\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=8,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 3.2580 - accuracy: 0.3682 - val_loss: 1.8544 - val_accuracy: 0.6430\n",
            "Epoch 2/8\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.6550 - accuracy: 0.6848 - val_loss: 1.3245 - val_accuracy: 0.7060\n",
            "Epoch 3/8\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.1383 - accuracy: 0.7669 - val_loss: 1.1272 - val_accuracy: 0.7560\n",
            "Epoch 4/8\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.8592 - accuracy: 0.8212 - val_loss: 1.0448 - val_accuracy: 0.7730\n",
            "Epoch 5/8\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.6758 - accuracy: 0.8640 - val_loss: 0.9823 - val_accuracy: 0.7960\n",
            "Epoch 6/8\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.5461 - accuracy: 0.8901 - val_loss: 0.9354 - val_accuracy: 0.8010\n",
            "Epoch 7/8\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.4257 - accuracy: 0.9107 - val_loss: 0.9000 - val_accuracy: 0.8190\n",
            "Epoch 8/8\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.3517 - accuracy: 0.9313 - val_loss: 0.8837 - val_accuracy: 0.8160\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.9694 - accuracy: 0.7845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA5f_WNgKAW0",
        "outputId": "810e146d-02c6-4cee-9b54-520317da6259"
      },
      "source": [
        "# 看一下最终结果\n",
        "results"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9694028496742249, 0.7845057845115662]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5WioSsAKY2i",
        "outputId": "44a10e67-e3da-4954-821c-817fc85f1d20"
      },
      "source": [
        "# 看一下完全随机的分类精度，比19%稍微高一点\n",
        "import copy\n",
        "\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19412288512911843"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5SEiEthKv5H",
        "outputId": "f29a5a3f-9b58-4913-b267-3f1bd8e77e86"
      },
      "source": [
        "# 这种方法可以得到约 80% 的精度。对于平衡的二分类问题，完全随机的分类器能够得到50%的精度。\n",
        "# 但在这个例子中，完全随机的精度约为19%，我估计训练9轮可能精度也只会在19%上下，所以就不再演示9个epochs的结果了。\n",
        "# 下面看一下在新数据上生成预测结果\n",
        "predictions = model.predict(x_test)\n",
        "predictions[0].shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E6yClmVLeWF",
        "outputId": "ae0446c9-245a-4505-d368-338ed041b1fc"
      },
      "source": [
        "# predictions 中的每个元素都是长度为 46 的向量，那么这个向量的所有元素总和呢\n",
        "np.sum(predictions[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fO45D4dLzre",
        "outputId": "583f13f2-f132-4c67-cf90-d583667b13a0"
      },
      "source": [
        "# 最大的元素就是预测类别，即概率最大的类别。\n",
        "np.argmax(predictions[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LOgHB6dMcMf"
      },
      "source": [
        "# 回到处理标签和损失的另一种方法：将标签列表转换为整数张量\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC2ugvCEOXbH"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2NJ7Tp4OiEo"
      },
      "source": [
        "对于这种编码方法，唯一需要改变的是损失函数的选择。对于one-hot encoding使用的损失\n",
        "函数 categorical_crossentropy，标签应该遵循分类编码。对于整数标签，你应该使用\n",
        "sparse_categorical_crossentropy。\n",
        "这个新的损失函数在数学上与 categorical_crossentropy 完全相同，二者只是接口不同。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmP54ycTObzT",
        "outputId": "42291164-5d0a-4c99-d8be-0d2fd1d09cac"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 20ms/step - loss: 3.6051 - accuracy: 0.0563 - val_loss: 2.8308 - val_accuracy: 0.2530\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 2.5815 - accuracy: 0.2782 - val_loss: 2.1223 - val_accuracy: 0.2870\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.8818 - accuracy: 0.3499 - val_loss: 1.6035 - val_accuracy: 0.6700\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.3748 - accuracy: 0.6944 - val_loss: 1.4336 - val_accuracy: 0.6740\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.1682 - accuracy: 0.7116 - val_loss: 1.3846 - val_accuracy: 0.6830\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.0718 - accuracy: 0.7244 - val_loss: 1.3395 - val_accuracy: 0.6970\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.9494 - accuracy: 0.7637 - val_loss: 1.3289 - val_accuracy: 0.7100\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.8824 - accuracy: 0.7814 - val_loss: 1.3181 - val_accuracy: 0.7190\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.7837 - accuracy: 0.8070 - val_loss: 1.3126 - val_accuracy: 0.7160\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.7081 - accuracy: 0.8277 - val_loss: 1.3622 - val_accuracy: 0.7170\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.6657 - accuracy: 0.8370 - val_loss: 1.3775 - val_accuracy: 0.7300\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.6403 - accuracy: 0.8417 - val_loss: 1.4014 - val_accuracy: 0.7260\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.5895 - accuracy: 0.8490 - val_loss: 1.4697 - val_accuracy: 0.7290\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.5662 - accuracy: 0.8484 - val_loss: 1.4735 - val_accuracy: 0.7190\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.5343 - accuracy: 0.8504 - val_loss: 1.5608 - val_accuracy: 0.7270\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.4956 - accuracy: 0.8583 - val_loss: 1.5941 - val_accuracy: 0.7250\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.4801 - accuracy: 0.8633 - val_loss: 1.6447 - val_accuracy: 0.7170\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.4434 - accuracy: 0.8659 - val_loss: 1.7009 - val_accuracy: 0.7210\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.4464 - accuracy: 0.8764 - val_loss: 1.7065 - val_accuracy: 0.7230\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.4182 - accuracy: 0.8799 - val_loss: 1.7750 - val_accuracy: 0.7170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f65ccc2ef10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSXGXwUbO_3n"
      },
      "source": [
        "### 中间层维度足够大的重要性\n",
        "前面用过的最终输出是 46 维的，因此中间层的隐藏单元个数不应该比 46 小太多。现在来\n",
        "试试，如果中间层的维度远远小于 46（比如 4 维），造成了信息瓶颈，那么会发生什么？\n",
        "- 结果还是比较直观的71.7%，已经接近72%了，比之前中间层使用46维的（81.6%）少了10%！\n",
        "- 分析一下原因，我认为下降这么多，将大量信息（这些信息足够恢复 46 个类别的分割超平面）压缩到维度很小的中间空间。网络能够将大部分必要信息塞入这个四维表示中，但并不可避免丢掉一些必要的信息，而这两部分信息的总和才是全部必要的信息。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xIDfYnYQRcq",
        "outputId": "709f4678-b2b0-4d4b-d9ea-86af69d7d54c"
      },
      "source": [
        "# 继续实验，这次中间层的隐藏单元是‘32’，其他条件不变\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 20ms/step - loss: 2.4675 - accuracy: 0.5042 - val_loss: 1.2843 - val_accuracy: 0.7060\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.7142 - accuracy: 0.8520 - val_loss: 0.9198 - val_accuracy: 0.8000\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.5161 - accuracy: 0.8907 - val_loss: 0.8925 - val_accuracy: 0.8100\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.3678 - accuracy: 0.9258 - val_loss: 0.8617 - val_accuracy: 0.8230\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.2829 - accuracy: 0.9380 - val_loss: 0.8828 - val_accuracy: 0.8250\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.2280 - accuracy: 0.9454 - val_loss: 0.9174 - val_accuracy: 0.8230\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1750 - accuracy: 0.9550 - val_loss: 0.9799 - val_accuracy: 0.8110\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1610 - accuracy: 0.9582 - val_loss: 1.0172 - val_accuracy: 0.8070\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1349 - accuracy: 0.9606 - val_loss: 1.0378 - val_accuracy: 0.8020\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1233 - accuracy: 0.9637 - val_loss: 1.0512 - val_accuracy: 0.8160\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1217 - accuracy: 0.9610 - val_loss: 1.0749 - val_accuracy: 0.7900\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1210 - accuracy: 0.9590 - val_loss: 1.1413 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1216 - accuracy: 0.9575 - val_loss: 1.1524 - val_accuracy: 0.8030\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1159 - accuracy: 0.9562 - val_loss: 1.1660 - val_accuracy: 0.8080\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1088 - accuracy: 0.9588 - val_loss: 1.2343 - val_accuracy: 0.8010\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1043 - accuracy: 0.9574 - val_loss: 1.1800 - val_accuracy: 0.8030\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1012 - accuracy: 0.9635 - val_loss: 1.2411 - val_accuracy: 0.8040\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0920 - accuracy: 0.9627 - val_loss: 1.1650 - val_accuracy: 0.7990\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0891 - accuracy: 0.9664 - val_loss: 1.2480 - val_accuracy: 0.8020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f65bee69ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py_gV8a8Q512"
      },
      "source": [
        "分类精度80.2%，对比下，下降还可以接受"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MH-QCHaRF6Z",
        "outputId": "b78c4653-8a8b-4a55-ec5f-6cbc4464f3e1"
      },
      "source": [
        "# 最后实验一下，这次中间层的隐藏单元是‘128’，其他条件不变\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 20ms/step - loss: 2.3047 - accuracy: 0.5131 - val_loss: 1.1974 - val_accuracy: 0.7330\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.9819 - accuracy: 0.7884 - val_loss: 0.9902 - val_accuracy: 0.7780\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.6152 - accuracy: 0.8642 - val_loss: 0.9142 - val_accuracy: 0.8060\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.3963 - accuracy: 0.9168 - val_loss: 0.8696 - val_accuracy: 0.8250\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.2733 - accuracy: 0.9368 - val_loss: 0.9255 - val_accuracy: 0.8170\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.2052 - accuracy: 0.9497 - val_loss: 0.9317 - val_accuracy: 0.8130\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1706 - accuracy: 0.9572 - val_loss: 0.9549 - val_accuracy: 0.8050\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1548 - accuracy: 0.9568 - val_loss: 1.0655 - val_accuracy: 0.8030\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1411 - accuracy: 0.9563 - val_loss: 1.0660 - val_accuracy: 0.7980\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1308 - accuracy: 0.9583 - val_loss: 1.2207 - val_accuracy: 0.7780\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1145 - accuracy: 0.9627 - val_loss: 1.0502 - val_accuracy: 0.7980\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1063 - accuracy: 0.9643 - val_loss: 1.1024 - val_accuracy: 0.7990\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1108 - accuracy: 0.9579 - val_loss: 1.0703 - val_accuracy: 0.8060\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0957 - accuracy: 0.9639 - val_loss: 1.2082 - val_accuracy: 0.8000\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0917 - accuracy: 0.9676 - val_loss: 1.0897 - val_accuracy: 0.8030\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0952 - accuracy: 0.9606 - val_loss: 1.1445 - val_accuracy: 0.8090\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0954 - accuracy: 0.9613 - val_loss: 1.1879 - val_accuracy: 0.7990\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.0865 - accuracy: 0.9623 - val_loss: 1.2214 - val_accuracy: 0.7900\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.0814 - accuracy: 0.9652 - val_loss: 1.2655 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.0818 - accuracy: 0.9646 - val_loss: 1.2271 - val_accuracy: 0.8030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f65be4ad8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1jzjhOfRoXf"
      },
      "source": [
        "中间层的隐藏单元个数达到128之后，分类反而下降到和32层相当，我猜想极可能是因为隐藏层中的神经元（隐藏单元）过多而导致的过拟合(overfitting)。当神经网络具有过多的节点（过多的信息处理能力）时，训练集中包含的有限信息量（相比128层就太少了）不足以训练隐藏层中的所有神经元，因此就会导致过拟合。即使训练数据包含的信息量足够，隐藏层中过多的神经元会增加训练时间，从而难以达到预期的效果。就这样啦！"
      ]
    }
  ]
}